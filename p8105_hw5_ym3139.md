p8105_hw5_ym3139
================
Yutong Mao (UNI: ym3139)
2025-11-13

# Problem 0

For this assignment, I created a public GitHub repository named
`p8105_hw5_ym3139` along with an R project of the same name. All data
files required for the assignment are stored in the `data/` subdirectory
and accessed via relative paths. All code for Problems 1 through 3 is
contained within a single R Markdown file, `p8105_hw5_ym3139.Rmd`, which
is rendered in `github_document` format.

# Problem 1

In this study, I employed a simulation approach to investigate the
birthday paradox. For groups ranging from 2 to 50 individuals, I
estimated the probability that at least two members share the same
birthday through 10,000 simulation runs.

``` r
# Function to simulate birthdays for a group and check for duplicates
check_birthday_match <- function(n) {
  
  # Simulate n birthdays as integers from 1 to 365
  birthdays <- sample(1:365, size = n, replace = TRUE)
  
  # Check whether there is at least one duplicated birthday
  any_duplicated <- any(duplicated(birthdays))
  
  # Return TRUE if there is a shared birthday, FALSE otherwise
  any_duplicated
}
```

``` r
check_birthday_match(2)    # very small group, low chance of match
```

    ## [1] FALSE

``` r
check_birthday_match(50)   # larger group, higher chance of match
```

    ## [1] TRUE

``` r
set.seed(1)  # set seed for reproducibility

# Create a data frame of all simulation settings
bday_sim_results <- 
  expand_grid(
    group_size = 2:50,      # number of people in the room
    iter       = 1:10000    # simulation iteration index
  ) |>
  mutate(
    # For each row, run the birthday function once
    has_match = map_lgl(group_size, check_birthday_match)
  ) |>
  group_by(group_size) |>
  summarize(
    # Estimated probability of at least one shared birthday
    prob_match = mean(has_match)
  )

# Look at the first few rows of the results
bday_sim_results
```

    ## # A tibble: 49 × 2
    ##    group_size prob_match
    ##         <int>      <dbl>
    ##  1          2     0.0024
    ##  2          3     0.0085
    ##  3          4     0.0167
    ##  4          5     0.0267
    ##  5          6     0.0399
    ##  6          7     0.0521
    ##  7          8     0.0751
    ##  8          9     0.0925
    ##  9         10     0.116 
    ## 10         11     0.139 
    ## # ℹ 39 more rows

``` r
# Plot the estimated probability as a function of group size
bday_sim_results |>
  ggplot(aes(x = group_size, y = prob_match)) +
  geom_line() +
  geom_point() +
  labs(
    x = "Group size (number of people)",
    y = "Estimated probability of shared birthday",
    title = "Birthday problem: simulation-based estimates"
  )
```

![](p8105_hw5_ym3139_files/figure-gfm/problem1-plot-1.png)<!-- -->

As shown in the chart, the probability of at least two people sharing a
birthday increases rapidly as the group size expands. When fewer than 10
people are in the room, this probability approaches 0; when the group
size reaches just over 20 people, the probability is approximately 0.5;
and when the number of people reaches around 50, the probability
approaches 1. This suggests that our intuition about the birthday
problem may underestimate how quickly the probability increases with
group size.

# Problem 2

In this study, I employed simulation methods to examine the test power
of the one-sample t-test under different conditions of true population
means. The sample size was fixed at $n = 30$, and the standard deviation
was fixed at $\sigma = 5$.

``` r
# Function to simulate one dataset and run a one-sample t-test
sim_one_ttest <- function(mu, n = 30, sigma = 5) {
  
  # Generate n observations from Normal(mu, sigma)
  x <- rnorm(n, mean = mu, sd = sigma)
  
  # Perform one-sample t-test for H0: mu = 0
  t_out <- t.test(x, mu = 0)
  
  # Use broom::tidy to extract estimate and p-value
  t_tidy <- broom::tidy(t_out)
  
  # Return a tibble with the sample mean and p-value
  tibble(
    mu_hat  = t_tidy$estimate,   # sample mean
    p_value = t_tidy$p.value     # p-value for H0: mu = 0
  )
}
```

``` r
sim_one_ttest(mu = 0)
```

    ## # A tibble: 1 × 2
    ##   mu_hat p_value
    ##    <dbl>   <dbl>
    ## 1  -1.62  0.0545

``` r
sim_one_ttest(mu = 3)
```

    ## # A tibble: 1 × 2
    ##   mu_hat p_value
    ##    <dbl>   <dbl>
    ## 1   2.46  0.0141

``` r
set.seed(1)  # set seed for reproducibility

# Run 5000 simulations for each true value of mu
ttest_results <- 
  expand_grid(
    true_mu = 0:6,          # true mean values
    iter    = 1:5000        # simulation iteration index
  ) |>
  mutate(
    # For each row, simulate one dataset and run the t-test
    sim_df = map(true_mu, sim_one_ttest)
  ) |>
  unnest(sim_df) |>
  mutate(
    # Indicator for rejecting the null at alpha = 0.05
    reject_null = p_value < 0.05
  )

# Take a quick look at the simulated results
ttest_results |> head()
```

    ## # A tibble: 6 × 5
    ##   true_mu  iter mu_hat p_value reject_null
    ##     <int> <int>  <dbl>   <dbl> <lgl>      
    ## 1       0     1  0.412  0.629  FALSE      
    ## 2       0     2  0.664  0.368  FALSE      
    ## 3       0     3  0.551  0.534  FALSE      
    ## 4       0     4  0.567  0.487  FALSE      
    ## 5       0     5 -1.65   0.0599 FALSE      
    ## 6       0     6  1.19   0.229  FALSE

``` r
# Compute the power (proportion of rejections) for each true mu
power_results <- 
  ttest_results |>
  group_by(true_mu) |>
  summarize(
    power = mean(reject_null)   # proportion of times H0 is rejected
  )

power_results
```

    ## # A tibble: 7 × 2
    ##   true_mu  power
    ##     <int>  <dbl>
    ## 1       0 0.0508
    ## 2       1 0.189 
    ## 3       2 0.568 
    ## 4       3 0.887 
    ## 5       4 0.992 
    ## 6       5 1     
    ## 7       6 1

``` r
# Plot power (proportion of rejections) vs true mu
power_results |>
  ggplot(aes(x = true_mu, y = power)) +
  geom_line() +
  geom_point() +
  labs(
    x = "True value of mu",
    y = "Power (proportion of rejections)",
    title = "Power of one-sample t-test as a function of the true mean"
  )
```

![](p8105_hw5_ym3139_files/figure-gfm/problem2-power-plot-1.png)<!-- -->

The figure shows that the power of the one-sample t-test gradually
increases as the true mean moves away from zero. When the true mean is
zero, the rejection probability approaches the nominal Type I error rate
of 0.05. As the true mean increases from 1 to 6, the test power steadily
rises and approaches 1. This indicates a positive correlation between
effect size and test power: the larger the effect, the easier it is to
detect.

As the true mean moves farther from 0 (i.e., the effect size increases),
the test’s power rises; when μ=0, the rejection rate approaches 0.05,
but as μ increases, power rapidly approaches 1.

``` r
# Compute average estimates of mu_hat
mu_estimates <- 
  ttest_results |>
  group_by(true_mu) |>
  summarize(
    avg_mu_hat_all    = mean(mu_hat),                # mean over all samples
    avg_mu_hat_reject = mean(mu_hat[reject_null])    # mean only when H0 is rejected
  )

mu_estimates
```

    ## # A tibble: 7 × 3
    ##   true_mu avg_mu_hat_all avg_mu_hat_reject
    ##     <int>          <dbl>             <dbl>
    ## 1       0      -0.000262            0.0426
    ## 2       1       0.996               2.21  
    ## 3       2       2.00                2.60  
    ## 4       3       2.99                3.18  
    ## 5       4       3.99                4.01  
    ## 6       5       5.01                5.01  
    ## 7       6       6.02                6.02

``` r
# Reshape to long format for plotting
mu_estimates_long <- 
  mu_estimates |>
  pivot_longer(
    avg_mu_hat_all:avg_mu_hat_reject,
    names_to  = "estimate_type",
    values_to = "avg_estimate"
  ) |>
  mutate(
    # Give more descriptive labels for plotting
    estimate_type = recode(
      estimate_type,
      avg_mu_hat_all    = "All samples",
      avg_mu_hat_reject = "Samples with rejection"
    )
  )

mu_estimates_long
```

    ## # A tibble: 14 × 3
    ##    true_mu estimate_type          avg_estimate
    ##      <int> <chr>                         <dbl>
    ##  1       0 All samples               -0.000262
    ##  2       0 Samples with rejection     0.0426  
    ##  3       1 All samples                0.996   
    ##  4       1 Samples with rejection     2.21    
    ##  5       2 All samples                2.00    
    ##  6       2 Samples with rejection     2.60    
    ##  7       3 All samples                2.99    
    ##  8       3 Samples with rejection     3.18    
    ##  9       4 All samples                3.99    
    ## 10       4 Samples with rejection     4.01    
    ## 11       5 All samples                5.01    
    ## 12       5 Samples with rejection     5.01    
    ## 13       6 All samples                6.02    
    ## 14       6 Samples with rejection     6.02

``` r
# Plot average mu_hat vs true mu for all samples and rejected samples
mu_estimates_long |>
  ggplot(aes(x = true_mu, y = avg_estimate, color = estimate_type)) +
  geom_line() +
  geom_point() +
  labs(
    x = "True value of mu",
    y = "Average of mu_hat",
    color = "Estimate type",
    title = "Average estimates of mu across all samples and rejected samples"
  )
```

![](p8105_hw5_ym3139_files/figure-gfm/problem2-mu-estimates-plot-1.png)<!-- -->

Across all samples, the average of μ̂ approximates the true value $\mu$
under each setting, consistent with the property of sample means as
unbiased estimators.

However, when averaging μ̂ only from samples that reject the null
hypothesis, the resulting mean exceeds the true value $\mu$. This
indicates selection bias: we condition only on events where the observed
mean is far from zero and yields a small p-value. Therefore, in
hypothesis rejection tests, the sample mean of μ̂ does not approximate
the true value $\mu$.

# Problem 3

In this study, I utilized homicide data from 50 major U.S. cities to
analyze the proportion of unsolved homicides in each city.

``` r
# Read in homicide data from the local data/ folder
homicide_df <- 
  read_csv("data/homicide-data.csv")

# Take a quick look at the raw data structure
homicide_df |> 
  glimpse()
```

    ## Rows: 52,179
    ## Columns: 12
    ## $ uid           <chr> "Alb-000001", "Alb-000002", "Alb-000003", "Alb-000004", …
    ## $ reported_date <dbl> 20100504, 20100216, 20100601, 20100101, 20100102, 201001…
    ## $ victim_last   <chr> "GARCIA", "MONTOYA", "SATTERFIELD", "MENDIOLA", "MULA", …
    ## $ victim_first  <chr> "JUAN", "CAMERON", "VIVIANA", "CARLOS", "VIVIAN", "GERAL…
    ## $ victim_race   <chr> "Hispanic", "Hispanic", "White", "Hispanic", "White", "W…
    ## $ victim_age    <chr> "78", "17", "15", "32", "72", "91", "52", "52", "56", "4…
    ## $ victim_sex    <chr> "Male", "Male", "Female", "Male", "Female", "Female", "M…
    ## $ city          <chr> "Albuquerque", "Albuquerque", "Albuquerque", "Albuquerqu…
    ## $ state         <chr> "NM", "NM", "NM", "NM", "NM", "NM", "NM", "NM", "NM", "N…
    ## $ lat           <dbl> 35.09579, 35.05681, 35.08609, 35.07849, 35.13036, 35.151…
    ## $ lon           <dbl> -106.5386, -106.7153, -106.6956, -106.5561, -106.5810, -…
    ## $ disposition   <chr> "Closed without arrest", "Closed by arrest", "Closed wit…

The raw dataset contains one record per homicide case, with variables
describing the city, state, year, geographic location, victim
demographics, and case disposition (e.g., “closed with arrest,”
“unresolved/no arrest”). The data covers over 50,000 homicides across 50
major U.S. cities.

``` r
# Create city_state and summarize total and unsolved homicides per city
city_summary <- 
  homicide_df |>
  mutate(
    # Combine city and state into a single variable
    city_state = str_c(city, ", ", state),
    # Indicator for unsolved cases
    unsolved = disposition %in% c("Closed without arrest", "Open/No arrest")
  ) |>
  group_by(city_state) |>
  summarize(
    total_homicides   = n(),                  # total cases in the city
    unsolved_homicides = sum(unsolved)        # number of unsolved cases
  ) |>
  ungroup()

city_summary |> 
  head()
```

    ## # A tibble: 6 × 3
    ##   city_state      total_homicides unsolved_homicides
    ##   <chr>                     <int>              <int>
    ## 1 Albuquerque, NM             378                146
    ## 2 Atlanta, GA                 973                373
    ## 3 Baltimore, MD              2827               1825
    ## 4 Baton Rouge, LA             424                196
    ## 5 Birmingham, AL              800                347
    ## 6 Boston, MA                  614                310

For each city, I created a `city_state` variable (e.g., “Baltimore,
Maryland”) and aggregated the total number of homicides and unsolved
homicides for that city. ‘Unsolved’ includes cases classified as “closed
without arrest” or “active/no arrest.”

``` r
# Filter to Baltimore, MD and extract counts
baltimore_counts <- 
  city_summary |>
  filter(city_state == "Baltimore, MD")

# Run prop.test for the proportion of unsolved homicides
baltimore_test <- 
  prop.test(
    x = baltimore_counts$unsolved_homicides,
    n = baltimore_counts$total_homicides
  )

# Tidy the prop.test output
baltimore_tidy <- 
  broom::tidy(baltimore_test)

baltimore_tidy
```

    ## # A tibble: 1 × 8
    ##   estimate statistic  p.value parameter conf.low conf.high method    alternative
    ##      <dbl>     <dbl>    <dbl>     <int>    <dbl>     <dbl> <chr>     <chr>      
    ## 1    0.646      239. 6.46e-54         1    0.628     0.663 1-sample… two.sided

``` r
# Pull the estimated proportion and confidence interval
baltimore_estimate <- baltimore_tidy |> pull(estimate)
baltimore_ci_low   <- baltimore_tidy |> pull(conf.low)
baltimore_ci_high  <- baltimore_tidy |> pull(conf.high)

baltimore_estimate
```

    ##         p 
    ## 0.6455607

``` r
baltimore_ci_low
```

    ## [1] 0.6275625

``` r
baltimore_ci_high
```

    ## [1] 0.6631599

For Baltimore, MD, the estimated proportion of homicides that are
unsolved is 0.646, with a 95% confidence interval from 0.628 to 0.663.

``` r
# Run prop.test for each city using map2 and list columns
city_prop_results <- 
  city_summary |>
  mutate(
    # List column with prop.test objects for each city
    prop_test = map2(
      unsolved_homicides, 
      total_homicides,
      ~ prop.test(x = .x, n = .y)
    ),
    # Tidy each prop.test result
    prop_tidy = map(prop_test, broom::tidy)
  ) |>
  # Keep only the city_state and the tidied results
  select(city_state, prop_tidy) |>
  unnest(prop_tidy) |>
  # Rename key columns for clarity
  rename(
    prop_unsolved = estimate,
    ci_low        = conf.low,
    ci_high       = conf.high
  )

city_prop_results |> 
  head()
```

    ## # A tibble: 6 × 9
    ##   city_state    prop_unsolved statistic  p.value parameter ci_low ci_high method
    ##   <chr>                 <dbl>     <dbl>    <dbl>     <int>  <dbl>   <dbl> <chr> 
    ## 1 Albuquerque,…         0.386   19.1    1.23e- 5         1  0.337   0.438 1-sam…
    ## 2 Atlanta, GA           0.383   52.5    4.32e-13         1  0.353   0.415 1-sam…
    ## 3 Baltimore, MD         0.646  239.     6.46e-54         1  0.628   0.663 1-sam…
    ## 4 Baton Rouge,…         0.462    2.27   1.32e- 1         1  0.414   0.511 1-sam…
    ## 5 Birmingham, …         0.434   13.8    2.05e- 4         1  0.399   0.469 1-sam…
    ## 6 Boston, MA            0.505    0.0407 8.40e- 1         1  0.465   0.545 1-sam…
    ## # ℹ 1 more variable: alternative <chr>

Using a clean pipeline with list-comprehensions and the `map2` function,
I applied the `prop.test` function to each city to estimate the
proportion of unsolved homicides and its 95% confidence interval.

``` r
# Reorder cities by estimated proportion of unsolved homicides
city_prop_results_ordered <- 
  city_prop_results |>
  mutate(
    city_state = fct_reorder(city_state, prop_unsolved)
  )

# Plot estimated proportions and confidence intervals by city
city_prop_results_ordered |>
  ggplot(aes(x = city_state, y = prop_unsolved)) +
  geom_point() +
  geom_errorbar(
    aes(ymin = ci_low, ymax = ci_high),
    width = 0
  ) +
  coord_flip() +
  labs(
    x = "City",
    y = "Estimated proportion of unsolved homicides",
    title = "Proportion of unsolved homicides by city",
    caption = "95% confidence intervals from prop.test"
  )
```

![](p8105_hw5_ym3139_files/figure-gfm/problem3-plot-1.png)<!-- -->

Cities are ranked by their proportion of unsolved homicides. Some cities
(such as those in the top region of the chart) exhibit relatively low
proportions of unsolved homicides with narrower confidence intervals,
indicating more stable clearance rates. Other cities show significantly
higher proportions of unsolved homicides, with point estimates exceeding
0.6 and wider confidence intervals.
